---
title: "Dis Manibus Segregation in RE"
author: "Adela Sobotkova"
date: "29/03/2022"
output:
  rmdformats::readthedown:
  highlight: kate
---

```{r setup, include=FALSE}
library(knitr)
library(rmdformats)

## Global options
options(max.print="75")
opts_chunk$set(echo=TRUE,
               cache=TRUE,
               prompt=FALSE,
               tidy=TRUE,
               comment=NA,
               message=FALSE,
               warning=FALSE)
opts_knit$set(width=75)
```

In this exercise you will map the ancient equivalent of Twitter data: the ancient inscriptions. Ancient people of class, education, and means liked to advertise their achievements and life milestones as well as their sorrows via the means of texts inscribed in stone. These epigraphic monuments were often placed near inhabited areas, roads, and gathering places where they were likely to attract the largest audience. The location of these self-expressions in space and time is a reasonable indicator of changing economic prosperity of the commissioning communities. In this exercise, you will explore how these ancient inscriptions spatially correspond to the distribution of ancient cities and settlements.  

```{r libraries, include=FALSE}
library(sf)
library(raster)
library(tidyverse)
library(leaflet)
```


# Task 1: Get spatial data for Roman Provinces


```{r load-province-data}
provinces <- st_read("https://raw.githubusercontent.com/pelagios/magis-pleiades-regions/main/pleiades-regions-magis-pelagios.geojson")
plot(provinces$geometry)
unique(provinces$name) %>% sort()
Spain <- provinces %>% filter(name %in% c("Lusitania", "Baetica", "Hispaniae")) %>% st_transform(3035)
plot(Spain$geometry); plot(inscriptions$geometry, add =T)

RE <- st_union(provinces) %>% st_transform(3035)
plot(RE)
```

# Task 2: Load DM inscriptions

```{r DM-Roman Empire}
# Load DM data for Spain
library(jsonlite)

# massive 225Mb datset - disrecommended
#list_json <- jsonlite::fromJSON("C:/Users/Adela/Documents/RStudio/sdam/EDH_exploration/data/EDH_dis_manibus_2021-08-12.json")

# small 40kb new dataset from March 2022
list_json <- jsonlite::fromJSON("C:/Users/au616760/Documents/RStudio/SDAM/EDH_exploration/data/EDH_DM.json")


# small temporal slices
list_json <- jsonlite::fromJSON("C:/Users/Adela/Documents/RStudio/sdam/EDH_exploration/data/EDH_dis_manibus_2021-08-12.json")
inscriptions = as_tibble(list_json)

# Check the first couple lines and column names
head(inscriptions)

# Wrangle the coordinates into a 2-column format - practice on a small dataset
# i_sm <- inscriptions %>% 
#   slice(1:100) %>% 
#   separate(col = coordinates, into = c("longitude","latitude"), sep = ",") %>%
#   mutate(latitude = as.numeric(gsub("_________","",latitude)),
#          longitude = as.numeric(gsub("_________","",longitude))) 

# Make a simple feature
library(sf)
inscriptions <- inscriptions %>% 
  filter(!is.na(longitude)) %>% 
  st_as_sf(coords = c("longitude", "latitude"), crs = 4326) %>% 
  st_transform(3035)

plot(inscriptions$geometry); plot(RE, add =T)
```

## Get Spain for test
```{r Spain, eval = FALSE}
# Get just Spain
library(tidyverse)

# On Home Dell
# inscriptions <- read_csv("C:/Users/Adela/Documents/RStudio/sdam/EDH_exploration/data/EDH_DM_Spain.csv")
# on Office Dell
inscriptions <- read_csv("C:/Users/au616760/Documents/RStudio/SDAM/EDH_exploration/data/EDH_DM_Spain.csv")
head(inscriptions)
names(inscriptions)

# Make a simple feature
library(sf)
inscriptions <- inscriptions %>% 
  filter(!is.na(longitude)) %>% 
  st_as_sf(coords = c("longitude", "latitude"), crs = 4326) %>% 
  st_transform(3035)

ch <- st_buffer(st_convex_hull(st_union(inscriptions)),100)
b <- st_make_grid(inscriptions, n=1)
plot(inscriptions$geometry); plot(b, add=T); plot(ch, border = "green", add=T)
```


Convert data into a ppp object
```{r}
# Libraries
library(spatstat)
library(spatialkernel)

# Data
pts <- as.matrix(st_coordinates(inscriptions))
marks <- inscriptions[["form_dis_manibus"]]

# Window
REbuff <- st_buffer(RE, 500)
plot(REbuff); plot(ch, add =T)
w <- as.owin(as_Spatial(st_sf(ch)))

# density
library(maptools)
i_ppp <- as.ppp(pts, W = w)
marks(i_ppp) <- as.factor(marks)
plot(i_ppp)
plot(density(i_ppp))

```
## Basic density
```{r}
i_spp <- split(i_ppp)
plot(density(i_spp))
```


## Look for optimal bandwidth
```{r}
# Scan from 1000m to 10000m in steps of 1000m
?spseg()

bw_choice <- spatialkernel::spseg(pts, marks, 
    h = seq(1000, 100000, by = 1000),
    opt = 1)

# Plot the results and highlight the best bandwidth
plotcv(bw_choice); abline(v = bw_choice$hcv, lty = 2, col = "red")

# Print the best bandwidth
print(bw_choice$hcv)  # 6000m
```

# Task 3: DM formula proportion estimation

```{r optimum-bandwith-sol, echo=FALSE, }

# Set the correct bandwidth and run for 10 simulations only
seg10 <- spatialkernel::spseg(
    pts = pts,
    marks = marks,
    h = 6000,
    opt = 3,
    ntest = 10,
    proc = FALSE,
    poly = as.matrix(st_coordinates(ch)[,1:2]))

seg10 <- readRDS("../data/DMseg10.rds")

# Plot the segregation map for different DIS MANIBUS formulae
unique(marks)
plotmc(seg10, "dis manibus")
plotmc(seg10, "dis manibus sacrum")
plotmc(seg10, "dii manes")


# save the seg10 object
#saveRDS(seg10, "../data/DMREseg10.rds")
```

Good work! The simulation shows that dms is relatively more frequent in the south of Spain, while dis manibus has a higher proportion in the north.


# Task 4: DM Segregation- Mapping segregation

With a base map and some image and contour functions we can display both the probabilities and the significance tests over the area with more control than the `plotmc()` function.

The `seg` object is a list with several components. The X and Y coordinates of the grid are stored in the `$gridx` and `$gridy` elements. The probabilities of each class of data (violent or non-violent crime) are in a matrix element `$p` with a column for each class. The p-value of the significance test is in a similar matrix element called `$stpvalue`. Rearranging columns of these matrices into a grid of values can be done with R's matrix() function. From there you can construct list objects with a vector `$x` of X-coordinates, `$y` of Y-coordinates, and `$z` as the matrix. You can then feed this to `image()` or `contour()` for visualization.

This process may seem complex, but remember that with R you can always write functions to perform complex tasks and those you may repeat often. For example, to help with the mapping in this exercise you will create a function that builds a map from four different items.

## Instructions

* Inspect the segregation object. 
  - Use `str()` to see the structure of `seg`. 
  - Set `ncol` as the length of one of the elements of `seg`.
* Create prob_violent as a list with 
  - x as the gridx element of `seg`. 
  - y as the gridy element. 
  - z as a matrix with the "dis manibus" column of the p element.
* Create `p_value` as in the previous step, except that the `z` element is logical, and `TRUE` when the `stpvalue` element of seg is less than 0.05.
* Call the `segmap()` function shown in the script to find areas where the probability of a crime being violent is above 0.15. Use 0.05 as the lower probability.

```{r segmap-dismanibus, echo=FALSE}
# Inspect the structure of the spatial segregation object
str(seg10)

# Get the number of columns in the data so we can rearrange to a grid
ncol <- length(seg10$gridy)

# Rearrange the probability column into a grid
prob_dismanibus <- list(x = seg10$gridx,
                     y = seg10$gridy,
                     z = matrix(seg10$p[, "dis manibus"],
                                ncol = ncol))
# You have basically georeferenced the image within data's coordinates
image(prob_dismanibus)

# Rearrange the p-values, but choose a p-value threshold
p_value <- list(x = seg10$gridx,
                y = seg10$gridy,
                z = matrix(seg10$stpvalue[, "dis manibus"]<= 0.1,
                                ncol = ncol))
contour(p_value)


# Create a mapping function
segmap <- function(prob_list, pv_list, low, high){

  # background map
  #library(raster)
  #plot(st_union(Spain$geometry))
  plot(REbuff)
  # p-value areas
  image(pv_list, 
        col = c("#00000000", "#FF808080"), add = TRUE) 

  # probability contours
  contour(prob_list,
          levels = c(low, high),
          col = c("#206020", "red"),
          labels = c("Low", "High"),
          add = TRUE)

  # boundary window
  plot(c, add = TRUE)
}

# Map the probability and p-value
segmap(prob_dismanibus, p_value, 0.11, 0.15)
```
```{r segmap-dismanibussacr, echo=FALSE}
# Inspect the structure of the spatial segregation object
str(seg10)

# Get the number of columns in the data so we can rearrange to a grid
ncol <- length(seg10$gridy)

# Rearrange the probability column into a grid
prob_dismanibuss <- list(x = seg10$gridx,
                     y = seg10$gridy,
                     z = matrix(seg10$p[, "dis manibus sacrum"],
                                ncol = ncol))
# You have basically georeferenced the image within data's coordinates
image(prob_dismanibuss)

# Rearrange the p-values, but choose a p-value threshold
p_value <- list(x = seg10$gridx,
                y = seg10$gridy,
                z = matrix(seg10$stpvalue[, "dis manibus sacrum"]< 0.11,
                                ncol = ncol))
contour(p_value)


# Map the probability and p-value
segmap(prob_dismanibuss, p_value, 0.11, 0.15)
```


# Task 5: Dissimilarity index

```{r seg-package-sol, echo=FALSE}
#install.packages("seg")
library(seg)

# data needs to be in a numeric matrix
library(tidyverse)
library(sf)
unique(inscriptions$form_dis_manibus_cons)
unique(inscriptions$form_dis_manibus)

unique(inscriptions$form_dis_manibus_ins)

i_data <- inscriptions %>% 
  dplyr::mutate(dismanibus = case_when(
    form_dis_manibus == "di manes" ~ 0,
     form_dis_manibus == "dii manes" ~ 0,
     form_dis_manibus == "dis manibus" ~ 1,
    form_dis_manibus == "diis manibus" ~ 1,
    form_dis_manibus == "dis manibus sacrum" ~ 0,
    form_dis_manibus == "diis manibus sacrum" ~ 0
    ),
    dismanibussacrum = case_when(
    form_dis_manibus == "di manes" ~ 0,
     form_dis_manibus == "dii manes" ~ 0,
     form_dis_manibus == "dis manibus" ~ 0,
    form_dis_manibus == "diis manibus" ~ 0,
    form_dis_manibus == "dis manibus sacrum" ~ 1,
    form_dis_manibus == "diis manibus sacrum" ~ 1 ),
    dimanes = case_when(
    form_dis_manibus == "di manes" ~ 1,
     form_dis_manibus == "dii manes" ~ 1,
     form_dis_manibus == "dis manibus" ~ 0,
    form_dis_manibus == "diis manibus" ~ 0,
    form_dis_manibus == "dis manibus sacrum" ~ 0,
    form_dis_manibus == "diis manibus sacrum" ~ 0)) %>% 
  dplyr::select(dismanibus, dismanibussacrum, dimanes) %>% st_drop_geometry()

# run the spseg() function
pp <- seg::spseg(x = st_coordinates(inscriptions), data=i_data, smoothing = "kernel", maxdist = 6000)

# Look at the results
print(pp, digits = 3)
spplot(pp, main = "Kernel")
help(spseg)
# To interpret the numbers check out Reardon and O'Sullivan's article
# https://onlinelibrary.wiley.com/doi/epdf/10.1111/j.0081-1750.2004.00150.x


detach("package:seg")

```
D is a measure of how different the composition of individual's local environments are , on  average, from the composition of the population as a whole. 
R is a measure of how much less diverse individuals' local environments are, on average, than is the total population of region R. It is based on spatially-weighted interaction index of population diversity (near locations contribute more than distant locations - distance-decay approach).
H is an aspatial measure of how much less diverse individuals' local environments are, on average, than is the total population of region R (entropy of local and overall envrionemt). 1 indicates maximum segregation, - when each indvidiuals' local environment is monoracial, for example. 0 indicates complete integration, when each individual's local environment has the same racial composition as the total population.

P spatial exposure of one group to another in local environment. Spatial isolation is the spatial exposure of group to itself

# Task 6: Start working with time

```{r load-centuries}
# Download json for 1st c CE

library(jsonlite)
# First century
download.file("https://sciencedata.dk/public/b6b6afdb969d378b70929e86e58ad975/formulae/EDH_DM_1CAD.json", "../data/EDH_DM1.json")
list_json <- jsonlite::fromJSON("../data/EDH_DM1.json")
CenturyOne <-  as_tibble(list_json)

# Second century
download.file("https://sciencedata.dk/public/b6b6afdb969d378b70929e86e58ad975/formulae/EDH_DM_2CAD.json", "../data/EDH_DM2.json")
list_json <- jsonlite::fromJSON("../data/EDH_DM2.json")
CenturyTwo <-  as_tibble(list_json)

# Third century
download.file("https://sciencedata.dk/public/b6b6afdb969d378b70929e86e58ad975/formulae/EDH_DM_3CAD.json", "../data/EDH_DM3.json")
list_json <- jsonlite::fromJSON("../data/EDH_DM3.json")
CenturyThree <-  as_tibble(list_json)


# Inspect
names(CenturyOne)
CenturyOne$random_dates
CenturyOne$date_var_1  # first list of random generated dates from use span interval

# Spatialize
i1 <- inscriptions %>% 
  filter(id%in%CenturyOne$id) # 7 fewer than in CenturyOne

i2 <- inscriptions %>% 
  filter(id%in%CenturyTwo$id) # over 200 ids fewer
length(which(duplicated(CenturyTwo$id)))

i3 <- inscriptions %>% 
  filter(id%in%CenturyThree$id) # 2000 missing


# Alternative spatialisation
i1 <- CenturyOne %>% filter(!is.na(latitude)) %>%  
  st_as_sf(coords = c("longitude", "latitude"), crs = 4326) %>% 
  st_transform(3035)

i2 <- CenturyTwo %>% filter(!is.na(latitude)) %>%  
  st_as_sf(coords = c("longitude", "latitude"), crs = 4326) %>% 
  st_transform(3035)

i3 <- CenturyThree %>% filter(!is.na(latitude)) %>%  
  st_as_sf(coords = c("longitude", "latitude"), crs = 4326) %>% 
  st_transform(3035)

plot(i1$geometry, col = "red")
plot(i2$geometry, col = "green", add =T)
plot(i3$geometry, col = "yellow", add =T) 
plot(RE, add= T)
```

# Task 7: DM segregation results in century-slices
My expectation is for higher values of segregation-isolation as aggregation will increase diversity.

## First century
```{r seg-1AD}
i1_data <- i1 %>% 
  dplyr::mutate(dismanibus = case_when(
    form_dis_manibus == "di manes" ~ 0,
     form_dis_manibus == "dii manes" ~ 0,
     form_dis_manibus == "dis manibus" ~ 1,
    form_dis_manibus == "diis manibus" ~ 1,
    form_dis_manibus == "dis manibus sacrum" ~ 0,
    form_dis_manibus == "diis manibus sacrum" ~ 0
    ),
    dismanibussacrum = case_when(
    form_dis_manibus == "di manes" ~ 0,
     form_dis_manibus == "dii manes" ~ 0,
     form_dis_manibus == "dis manibus" ~ 0,
    form_dis_manibus == "diis manibus" ~ 0,
    form_dis_manibus == "dis manibus sacrum" ~ 1,
    form_dis_manibus == "diis manibus sacrum" ~ 1 ),
    dimanes = case_when(
    form_dis_manibus == "di manes" ~ 1,
     form_dis_manibus == "dii manes" ~ 1,
     form_dis_manibus == "dis manibus" ~ 0,
    form_dis_manibus == "diis manibus" ~ 0,
    form_dis_manibus == "dis manibus sacrum" ~ 0,
    form_dis_manibus == "diis manibus sacrum" ~ 0)) %>% 
  dplyr::select(dismanibus, dismanibussacrum, dimanes) %>% st_drop_geometry()

# run the spseg() function
pp1 <- seg::spseg(x = st_coordinates(i1), data=i1_data, smoothing = "kernel", maxdist = 6000)

# Look at the results
print(pp1, digits = 3)
spplot(pp1, main = "Kernel")
help(spseg)
```
## Second century
```{r seg-2AD}
i2_data <- i2 %>% 
  dplyr::mutate(dismanibus = case_when(
    form_dis_manibus == "di manes" ~ 0,
     form_dis_manibus == "dii manes" ~ 0,
     form_dis_manibus == "dis manibus" ~ 1,
    form_dis_manibus == "diis manibus" ~ 1,
    form_dis_manibus == "dis manibus sacrum" ~ 0,
    form_dis_manibus == "diis manibus sacrum" ~ 0
    ),
    dismanibussacrum = case_when(
    form_dis_manibus == "di manes" ~ 0,
     form_dis_manibus == "dii manes" ~ 0,
     form_dis_manibus == "dis manibus" ~ 0,
    form_dis_manibus == "diis manibus" ~ 0,
    form_dis_manibus == "dis manibus sacrum" ~ 1,
    form_dis_manibus == "diis manibus sacrum" ~ 1 ),
    dimanes = case_when(
    form_dis_manibus == "di manes" ~ 1,
     form_dis_manibus == "dii manes" ~ 1,
     form_dis_manibus == "dis manibus" ~ 0,
    form_dis_manibus == "diis manibus" ~ 0,
    form_dis_manibus == "dis manibus sacrum" ~ 0,
    form_dis_manibus == "diis manibus sacrum" ~ 0)) %>% 
  dplyr::select(dismanibus, dismanibussacrum, dimanes) %>% st_drop_geometry()

# run the spseg() function
pp2 <- seg::spseg(x = st_coordinates(i2), data=i2_data, smoothing = "kernel", maxdist = 6000)

# Look at the results
print(pp2, digits = 3)
spplot(pp2, main = "Kernel")
help(spseg)
```

## Third century

```{r seg-3AD}
i3_data <- i3 %>% 
  dplyr::mutate(dismanibus = case_when(
    form_dis_manibus == "di manes" ~ 0,
     form_dis_manibus == "dii manes" ~ 0,
     form_dis_manibus == "dis manibus" ~ 1,
    form_dis_manibus == "diis manibus" ~ 1,
    form_dis_manibus == "dis manibus sacrum" ~ 0,
    form_dis_manibus == "diis manibus sacrum" ~ 0
    ),
    dismanibussacrum = case_when(
    form_dis_manibus == "di manes" ~ 0,
     form_dis_manibus == "dii manes" ~ 0,
     form_dis_manibus == "dis manibus" ~ 0,
    form_dis_manibus == "diis manibus" ~ 0,
    form_dis_manibus == "dis manibus sacrum" ~ 1,
    form_dis_manibus == "diis manibus sacrum" ~ 1 ),
    dimanes = case_when(
    form_dis_manibus == "di manes" ~ 1,
     form_dis_manibus == "dii manes" ~ 1,
     form_dis_manibus == "dis manibus" ~ 0,
    form_dis_manibus == "diis manibus" ~ 0,
    form_dis_manibus == "dis manibus sacrum" ~ 0,
    form_dis_manibus == "diis manibus sacrum" ~ 0)) %>% 
  dplyr::select(dismanibus, dismanibussacrum, dimanes) %>% st_drop_geometry()

# run the spseg() function
pp3 <- seg::spseg(x = st_coordinates(i3), data=i3_data, smoothing = "kernel", maxdist = 6000)

# Look at the results
print(pp3, digits = 3)
spplot(pp3, main = "Kernel")
help(spseg)
```


# Task 8: Space-time modelling with splancs?
Grab a random date for each inscription `i1$date_var_1` and use it to simulate a date
Aggrgate i1 - i3 and run space-tiem on it.

To do a space-time clustering test with `stmctest()` from the `splancs` package, you first need to convert parts of your `ppp` object. Functions in `splancs` tend to use matrix data instead of data frames.

To run `stmctest()` you need to set up the following:

- event locations
- event times
- region polygon
- time limits
- the time and space ranges for analysis.


```{r cluster-sol, echo=FALSE}
#Libraries
library(spatstat)
library(splancs)

# Data
i <- rbind(i1, i2, i3)

# Get a matrix of event coordinates
i_xy <- as.matrix(st_coordinates(i))

# Check the matrix has two columns
dim(i_xy)

# Get a vector of event times
names(i)
i_t <- i$date_var_1

# Extract a two-column matrix from the ppp object
i_poly <- as.matrix(as.data.frame(window))
dim(i_poly)

# Set the time limit to 1 day before and 1 day after the range of times
tlimits <- range(i_t) + c(-1, 1)

# Scan over 6000m intervals from 1000m to 20000km
s <- seq(1000, 20000, by = 6000)

# Scan over 14 day intervals from one week to 31 weeks
tm <- seq(1,400, by = 7)

```

Gosh, what a lot of set-up! Now for the action.
## Monte Carlo test 

Everything is now ready for you to run the space-time clustering test function. You can then plot the results and compute a `p-value` for rejecting the null hypothesis of no space-time clustering.

Any space-time clustering in a data set will be removed if you randomly rearrange the dates of the data points. The `stmctest()` function computes a clustering test statistic for your data based on the space-time K-function - how many points are within a spatial and temporal window of a point of the data. It then does a number of random rearrangements of the dates among the points and computes the clustering statistic. After doing this a large number of times, you can compare the test statistic for your data with the values from the random data. If the test statistic for your data is sufficiently large or small, you can reject the null hypothesis of no space-time clustering.

The output from `stmctest(`) is a list with a single `t0` which is the test statistic for your data, and a vector of `t` from the simulations. By converting to data frame you can feed this to `ggplot` functions.

Because the window area is a large number of square meters, and we have about 400 events, the numerical value of the intensity is a very small number. This makes values of the various K-functions very large numbers, since they are proportional to the inverse of the intensity. Don't worry if you see 10^10 or higher!

The `p-value` of a Monte-Carlo test like this is just the proportion of test statistics that are larger than the value from the data. You can compute this from the `t` and `t0` elements of the output.

## Instructions

* Ensure that all the objects from the previous exercise are loaded.
* Run `stmctest()` for 999 simulations.
* Draw a histogram of times.
* The x-aesthetic is `t`.
* Add a vertical line at the `t0` value.
* Sum up how many `t` values are larger than the `t0` value, and compute as a proportion. 

```{r MC-sol, echo=FALSE}
# Run 999 simulations 
i_mc <- stmctest(i_xy, i_t, i_poly, tlimits, s, tm, nsim = 99, quiet = TRUE)
names(i_mc)

# Histogram the simulated statistics and add a line at the data value
library(ggplot2)
ggplot(data.frame(i_mc), aes(x = t)) + 
  geom_histogram() + 
  geom_vline(aes(xintercept = t0))

# Compute the p-value as the proportion of tests greater than the data
sum(i_mc$t > i_mc$t0) / 1000
```
p = 0.099
Magnificent Monte Carlo simulation!

# Task 9: Space-time over DM formulae -- UNFINISHED, maybe meaningless?
Let's use the split-up i and model different formulae in space and time

```{r cluster-sol, echo=FALSE}
#Libraries
library(spatstat)
library(splancs)

# Data
i <- rbind(i1, i2, i3)
i <- cbind(i, century = c(rep(1,428), rep(2, 4959), rep(3,3137)))
# Get a matrix of event coordinates
i_xy <- as.matrix(st_coordinates(i %>% 
                                    filter(form_dis_manibus=="dis manibus")))

# Check the matrix has two columns
dim(i1_xy)

# Get a vector of event times
names(i1)
i1_t <- i1$date_var_1

# Extract a two-column matrix from the ppp object
i_poly <- as.matrix(as.data.frame(window))
dim(i_poly)

# Set the time limit to 1 day before and 1 day after the range of times
tlimits <- range(i_t) + c(-1, 1)

# Scan over 6000m intervals from 1000m to 20000km
s <- seq(1000, 20000, by = 6000)

# Scan over 14 day intervals from one week to 31 weeks
tm <- seq(1,400, by = 7)

```

# Task 10: Spatial clustering

```{r K-cross-sol}
kc <- Kcross(i_ppp, i = "dis manibus", j = "dis manibus sacrum")
plot(kc, . - pi * r ^ 2 ~ r)

#ekc <- envelope(i_ppp, Kcross, nsim = 50, i = "dis manibus", j = "dis manibus sacrum")
ekc <- readRDS("../data/DMekc.rds")
plot(ekc, . - pi * r ^ 2 ~ r)

saveRDS(ekc, "../data/DMekc.rds")
```


